{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570da7bf-ec22-487b-872e-47cec1c4084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "from diffusers.utils import export_to_gif\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "\n",
    "step = 4  # Options: [1,2,4,8]\n",
    "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
    "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
    "base = \"emilianJR/epiCRealism\"  # Choose to your favorite base model.\n",
    "\n",
    "adapter = MotionAdapter().to(device, dtype)\n",
    "adapter.load_state_dict(load_file(hf_hub_download(repo ,ckpt), device=device))\n",
    "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
    "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
    "\n",
    "output = pipe(prompt=\"A girl smiling\", guidance_scale=1.0, num_inference_steps=step)\n",
    "export_to_gif(output.frames[0], \"animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import TextToVideoZeroPipeline\n",
    "import numpy as np\n",
    "\n",
    "model_id = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "pipe = TextToVideoZeroPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\") #16 -> 32\n",
    "seed = 0\n",
    "video_length = 24 \n",
    "chunk_size = 8\n",
    "prompt = \"Morning of a rural area\"\n",
    "#pipe.enable_model_cpu_offload()\n",
    "# Generate the video chunk-by-chunk\n",
    "result = []\n",
    "chunk_ids = np.arange(0, video_length, chunk_size - 1)\n",
    "generator = torch.Generator(device=\"cuda\")\n",
    "for i in range(len(chunk_ids)):\n",
    "    print(f\"Processing chunk {i + 1} / {len(chunk_ids)}\")\n",
    "    ch_start = chunk_ids[i]\n",
    "    ch_end = video_length if i == len(chunk_ids) - 1 else chunk_ids[i + 1]\n",
    "    # Attach the first frame for Cross Frame Attention\n",
    "    frame_ids = [0] + list(range(ch_start, ch_end))\n",
    "    # Fix the seed for the temporal consistency\n",
    "    generator.manual_seed(seed)\n",
    "    output = pipe(prompt=prompt, video_length=len(frame_ids), generator=generator, frame_ids=frame_ids)\n",
    "    result.append(output.images[1:])\n",
    "\n",
    "# Concatenate chunks and save\n",
    "result = np.concatenate(result)\n",
    "result = [(r * 255).astype(\"uint8\") for r in result]\n",
    "imageio.mimsave(\"video.mp4\", result, fps=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
